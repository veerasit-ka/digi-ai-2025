{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x112e04f90>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x113683010>, root_client=<openai.OpenAI object at 0x111bf7150>, root_async_client=<openai.AsyncOpenAI object at 0x112ee3f50>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables.base import Runnable\n",
    "import os\n",
    "\n",
    "def chat_openai() -> Runnable:\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    llm = ChatOpenAI(\n",
    "        openai_api_key=openai_api_key,\n",
    "        model = \"gpt-4o-mini\",\n",
    "        temperature=0\n",
    "        )\n",
    "    return llm\n",
    "\n",
    "llm = chat_openai()\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3887204207.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31minput = \"\"\"\u001b[39m\n            ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
     ]
    }
   ],
   "source": [
    "# Global variable\n",
    "input = \"\"\"\n",
    "Rescuers are rushing to find people still trapped under collapsed buildings in quake-hit Myanmar as the crucial 72-hour mark approaches, when survival rates are said to drop sharply.\n",
    "Friday's magnitude 7.7 earthquake has claimed about 1,700 lives and injured some 3,400 people. Around 300 others remain unaccounted for.\n",
    "Mandalay, the second-largest city, saw widespread damage, including many collapsed buildings. The search continues for those believed to be trapped inside a large condominium building that mostly collapsed.\n",
    "Local officials say a Japanese national who lived in the building is unaccounted for. Japan's Foreign Ministry has asked Myanmar authorities, through its embassy in the country, to search for and rescue the Japanese national.\n",
    "Damage has also been reported in neighboring Thailand. A high-rise building under construction collapsed in the capital Bangkok.\n",
    "Thai authorities say at least 11 people were killed and more than 70 others remain unaccounted for.\n",
    "Search and rescue operations continue using large cranes and other equipment. More rescue workers are being brought in to speed up the search.\" \\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Question 1 (Summarization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1) Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_summarization = ChatPromptTemplate.from_template(\"\"\"\n",
    "Prompt...\n",
    "\n",
    "Here is the text:\n",
    "{input}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompt_summarization.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2) Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define chain summarization\n",
    "chain_summarization = prompt_summarization | llm\n",
    "chain_summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3) Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain_summarization.invoke({\n",
    "    \"input\": input\n",
    "})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Question 2 (Pydantic Parser)\n",
    "##### The answer should include:\n",
    "##### 1) The affected countries\n",
    "##### 2) The magnitude of the earthquake.\n",
    "##### 3) The number of injured people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_extraction = ChatPromptTemplate.from_template(\"\"\"\n",
    "Prompt...\n",
    "\n",
    "Here is the text:\n",
    "{input}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompt_extraction.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from typing import List, Dict, Any\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Output(BaseModel):\n",
    "    location: str = Field(description=\"...\")\n",
    "    # ...\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Output)\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Adding context of the output parser to the prompt\n",
    "prompt_extraction.messages.append(HumanMessage(\n",
    "    content=parser.get_format_instructions()\n",
    "))\n",
    "prompt_extraction.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define chain extraction\n",
    "chain_extraction: Runnable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3) Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain_extraction.invoke({\n",
    "    \"input\": input\n",
    "})\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Question 3 (Translation Chain & Consolidate to Sequential Chain) [OPTIONAL]\n",
    "##### Summarize -> Translation\n",
    "##### The answer should be provided by 1 invoke execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1) Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_translation = ChatPromptTemplate.from_template(\"\"\"\n",
    "Prompt...\n",
    "\n",
    "Here is the text:\n",
    "{input}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompt_extraction.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2) Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use chain summaize from question 1\n",
    "chain_summarize = prompt_extraction | llm\n",
    "chain_summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define chain translation\n",
    "chain_translation: Runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidate to Sequencial Chain\n",
    "chain_final: Runnable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3) Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain_final.invoke({\n",
    "    \"input\": input\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
